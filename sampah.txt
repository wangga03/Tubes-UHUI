import os
import pickle
from keras_facenet import FaceNet
import cv2
from sklearn.neighbors import KNeighborsClassifier
import numpy as np
import imgaug.augmenters as iaa
import sys
import contextlib

pkl_path = '/home/wgg/Tubes_AI/HASIL_FACENET/knn_facenet_aug3.pkl'

# --- Fungsi suppress stdout Keras ---
@contextlib.contextmanager
def suppress_stdout():
    with open(os.devnull, "w") as devnull:
        old_stdout = sys.stdout
        sys.stdout = devnull
        try:
            yield
        finally:
            sys.stdout = old_stdout

# --- INISIALISASI FACENET SELALU ---
embedder = FaceNet()

# === Jika file .pkl sudah ada, LOAD SAJA ===
if os.path.exists(pkl_path):
    print("Memuat model KNN dari file .pkl...")
    with open(pkl_path, 'rb') as f:
        knn = pickle.load(f)
    print("Model KNN siap digunakan!")

else:
    print("File .pkl belum ada, mulai proses ekstraksi embedding & training KNN...")

    X, y = [], []

    base_dir = "/home/wgg/Tubes_AI/dataset2/train"

    seq = iaa.Sequential([
        iaa.Fliplr(0.5),              
        iaa.Affine(rotate=(-10, 10)), 
        iaa.Multiply((0.8, 1.2)),     
        iaa.AddToHueAndSaturation((-10, 10)),
        iaa.GaussianBlur(sigma=(0, 1.0)),
    ])

    for label in os.listdir(base_dir):
        folder = os.path.join(base_dir, label)
        for file in os.listdir(folder):
            img_path = os.path.join(folder, file)
            img = cv2.imread(img_path)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            img = cv2.resize(img, (160, 160))
            
            with suppress_stdout():
                emb = embedder.embeddings([img])[0]
            X.append(emb)
            y.append(label)
            
            for i in range(3):
                aug_img = seq(image=img)
                with suppress_stdout():
                    aug_emb = embedder.embeddings([aug_img])[0]
                X.append(aug_emb)
                y.append(label)

    X = np.array(X)
    y = np.array(y)
    knn = KNeighborsClassifier(n_neighbors=3, metric='euclidean')
    knn.fit(X, y)

    # SIMPAN .pkl
    with open(pkl_path, 'wb') as f:
        pickle.dump(knn, f)
    print("Model KNN telah dilatih & disimpan ke .pkl!")

# --- Mulai webcam ---
face_cascade = cv2.CascadeClassifier('/home/wgg/Tubes_AI/haarcascade_frontalface_alt2.xml')
cap = cv2.VideoCapture(2)  # ganti index kamera jika perlu

while True:
    ret, frame = cap.read()
    if not ret:
        break

    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, 1.2, 5)

    pred = None  # Menetapkan prediksi default di luar loop wajah
    if len(faces) > 0:  # Jika ada wajah yang terdeteksi
        for (x, y, w, h) in faces:
            face = frame[y:y+h, x:x+w]
            if face.shape[0] > 0 and face.shape[1] > 0:
                img_rgb = cv2.cvtColor(cv2.resize(face, (160, 160)), cv2.COLOR_BGR2RGB)
                with suppress_stdout():
                    emb = embedder.embeddings([img_rgb])[0]
                pred = knn.predict([emb])[0]
                conf = knn.predict_proba([emb]).max()
                color = (0,255,0) if pred != 'jawa' else (0,0,255)
                cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)
                cv2.putText(frame, f"{pred} ({conf:.2f})", (x, y-10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)

    # Update tampilan di window
    cv2.imshow("FaceNet + KNN", frame)

    # Menghapus buffer terminal, kemudian update teks
    print("\033c", end="")  # Membersihkan terminal
    if pred == 'jawa':
        print(f"\033[31m{pred}\033[0m", end="\r", flush=True)  # Red text
    elif pred is None:  # Jika tidak ada wajah terdeteksi
        print(f"\033[33mTidak ada wajah terdeteksi\033[0m", end="\r", flush=True)  # Yellow text
    elif pred is not None:
        print(f"\033[32m{pred}\033[0m", end="\r", flush=True)  # Green text

    # Stop dengan 'q'
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
